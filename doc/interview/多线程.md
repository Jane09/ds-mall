### 线程的姿态
![线程状态](../images/thread.jpg)
#### 新建状态（New）
    线程对象被创建后，就进入了新建状态。例如，Thread thread = new Thread()
#### 就绪状态(Runnable)
    也被称为“可执行状态”。线程对象被创建后，其它线程调用了该对象的start()方法，从而来启动该线程。
    例如，thread.start()。处于就绪状态的线程，随时可能被CPU调度执行。
#### 运行状态(Running)
    线程获取CPU权限进行执行。需要注意的是，线程只能从就绪状态进入到运行状态
#### 阻塞状态(Blocked)
    阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。直到线程进入就绪状态，才有机会转到运行状态。阻塞的情况分三种：
    (01) 等待阻塞 -- 通过调用线程的wait()方法，让线程等待某工作的完成。
    (02) 同步阻塞 -- 线程在获取synchronized同步锁失败(因为锁被其它线程所占用)，它会进入同步阻塞状态。
    (03) 其他阻塞 -- 通过调用线程的sleep()或join()或发出了I/O请求时，线程会进入到阻塞状态。
        当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。
#### 死亡状态（Dead)
    线程执行完了或者因异常退出了run()方法，该线程结束生命周期。

### 进程和线程的区别
    它们是不同的操作系统资源管理方式
    进程有独立的 地址空间，一个进程崩溃后，在保护模式下不会对其它进程产生影响，而线程只是一个进程中的不同执行路径。
    线程有自己的堆栈和局部变量，但线程之间没有单独的地址空间，一个线程死掉就等于整个进程死掉，所以多进程的程序要比多线程的程序健壮，
    但在进程切换时，耗费资源较大，效率要差一些。

    一个程序至少有一个进程,一个进程至少有一个线程
    线程的划分尺度小于进程，使得多线程程序的并发性高
    进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率
    线程不能够独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制
    从逻辑角度来看，多线程的意义在于一个应用程序中，有多个执行部分可以同时执行。但操作系统并没有将多个线程看做多个独立的应用，来实现进程的调度和管理以及资源分配



    线程执行开销小，但不利于资源的管理和保护；而进程正相反

### Java创建线程之后，直接调用start()方法和run()的区别
    start -> 让线程处于可运行状态
    run() -> 线程获取到cpu权限的实际运行，结束后方法停止

### 假如我还想隔离两个线程的数据, 怎么办？

    ThreadLocal
    例子：

### 常用的线程池模式以及不同线程池的使用场景
    public ThreadPoolExecutor(int corePoolSize,
                                  int maximumPoolSize,
                                  long keepAliveTime,
                                  TimeUnit unit,
                                  BlockingQueue<Runnable> workQueue,
                                  ThreadFactory threadFactory,
                                  RejectedExecutionHandler handler) {
           ...
        }
    workQueue:
        LinkedBlockingQueue: 不设界限、无界限，cpu，内存飙升
        ArrayBlockingQueue：
        PriorityBlockingQueue
        SynchronousQueue
#### 有界队列
    遵循FIFO原则的队列如ArrayBlockingQueue与有界的LinkedBlockingQueue
    优先级队列如PriorityBlockingQueue
    有界队列时队列大小需和线程池大小互相配合
#### 同步移交
    如果不希望任务在队列中等待而是希望将任务直接移交给工作线程，可使用SynchronousQueue作为等待队列
    SynchronousQueue不是一个真正的队列，而是一种线程之间移交的机制
    要将一个元素放入SynchronousQueue中，必须有另一个线程正在等待接收这个元素。只有在使用无界线程池或者有饱和策略时才建议使用该队列
#### BlockingQueue具体的实现原理

#### 饱和策略选择RejectedExecutionHandler
##### AbortPolicy
    默认策略
    抛出RejectedExecutionException
##### DiscardPolicy抛弃策略
    直接抛弃
##### DiscardOldestPolicy抛弃旧任务策略
    先将阻塞队列中的头元素出队抛弃，再尝试提交任务。如果此时阻塞队列使用PriorityBlockingQueue优先级队列，将会导致优先级最高的任务被抛弃，因此不建议将该种策略配合优先级队列使用
##### CallerRunsPolicy调用者运行
    既不抛弃任务也不抛出异常，直接运行任务的run方法，换言之将任务回退给调用者来直接运行
    使用该策略时线程池饱和后将由调用线程池的主线程自己来执行任务，因此在执行任务的这段时间里主线程无法再提交新任务，从而使线程池中工作线程有时间将正在处理的任务处理完成。
#### 线程池类型
    Executors.
##### newCachedThreadPool
    public static ExecutorService newCachedThreadPool() {
            return new ThreadPoolExecutor(0, Integer.MAX_VALUE,
                                          60L, TimeUnit.SECONDS,
                                          new SynchronousQueue<Runnable>());
        }
    要将一个元素放入SynchronousQueue中，必须有另一个线程正在等待接收这个元素
    第一个任务到达时便会创建一个新线程执行该任务
    自动释放空闲线程
    动态调节线程池

##### newFixedThreadPool 固定长度，超出等待
    public static ExecutorService newFixedThreadPool(int nThreads) {
            return new ThreadPoolExecutor(nThreads, nThreads,
                                          0L, TimeUnit.MILLISECONDS,
                                          new LinkedBlockingQueue<Runnable>());
        }
    固定大小的线程池并使用无限大的队列
    newFixedThreadPool此种线程池如果线程数达到最大值后会怎么办，底层原理？
    执行期间被关闭则创建一个线程替代；最大等待；线程一直存在只要不显示关闭

##### newScheduledThreaPool 定长，支持周期性任务
    public ScheduledThreadPoolExecutor(int corePoolSize) {
            super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,
                  new DelayedWorkQueue());
        }
    DelayedWorkQueue是一个无界队列，它能按一定的顺序对工作队列中的元素进行排列
##### newSingleThreadPool 单线程线程池
    保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行
     public static ScheduledExecutorService newSingleThreadScheduledExecutor() {
            return new DelegatedScheduledExecutorService
                (new ScheduledThreadPoolExecutor(1));
        }
    使用装饰模式增强了ScheduledExecutorService（1）的功能，不仅确保只有一个线程顺序执行任务，也保证线程意外终止后会重新创建一个线程继续执行任务

##### newWorkStealingPool 一个拥有多个任务队列（以便减少连接数）的线程池
    public static ExecutorService newWorkStealingPool() {
            return new ForkJoinPool
                (Runtime.getRuntime().availableProcessors(),
                 ForkJoinPool.defaultForkJoinWorkerThreadFactory,
                 null, true);
        }
多线程引起资源竞争，如果改变状态可能出现与预期不一致的结果，所以引入锁机制来管理；数据的完整性
多线程为了协调工作，需要进行通信

### 线程间通信
1、全局变量
    保证全局变量的原子性，不能进行指令重排
    volatile
    AtomicInteger...
    CyclicBarrier
    PipedInputStream
    BlockingQueue
2、MQ
3、事件驱动类

### 了解可重入锁的含义，以及ReentrantLock 和synchronized的区别

    可重入锁
    可重复可递归调用的锁，在外层使用锁之后，在内层仍然可以使用，并且不发生死锁（前提得是同一个对象或者class）

    不可重入锁
    不可递归调用，递归调用就发生死锁


    都是可以重入的锁，锁计数器
    Synchronized是依赖于JVM实现的（操作系统），而ReenTrantLock是JDK实现的（自己写代码）
    性能区别：
        在Synchronized优化以前，synchronized的性能是比ReenTrantLock差很多的，
        但是自从Synchronized引入了偏向锁，轻量级锁（自旋锁）后，两者的性能就差不多了，在两种方法都可用的情况下，
        官方甚至建议使用synchronized，其实synchronized的优化我感觉就借鉴了ReenTrantLock中的CAS技术。
        都是试图在用户态就把加锁问题解决，避免进入内核态的线程阻塞。
    功能区别：
        很明显Synchronized的使用比较方便简洁，并且由编译器去保证锁的加锁和释放
        ReenTrantLock需要手工声明来加锁和释放锁，为了避免忘记手工释放锁造成死锁，所以最好在finally中声明释放锁
    粒度和灵活性
        ReentrantLock > Synchronized(公平锁)
    ReentrantLock独有：
        可以指定是公平锁还是非公平锁
        提供了一个Condition（条件）类，用来实现分组唤醒需要唤醒的线程们，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程
        提供了一种能够中断等待锁的线程的机制，通过lock.lockInterruptibly()来实现这个机制
### 同步的数据结构
#### CountDownLatch
#### ConcurrentLinkedQueue
#### ConcurrentHashMap
[参考](http://www.jasongj.com/java/concurrenthashmap/)

    JDK7
    基于分段锁的
  ![jconcurrentHashMap](../images/concurrenthashmap_java7.png)

    寻址方式
    在读写某个Key时，先取该Key的哈希值。并将哈希值的高N位对Segment个数取模从而得到该Key应该属于哪个Segment，
    接着如同操作HashMap一样操作这个Segment。为了保证不同的值均匀分布到不同的Segment，需要通过如下方法计算哈希值
    private int hash(Object k) {
      int h = hashSeed;
      if ((0 != h) && (k instanceof String)) {
        return sun.misc.Hashing.stringHash32((String) k);
      }
      h ^= k.hashCode();
      h += (h <<  15) ^ 0xffffcd7d;
      h ^= (h >>> 10);
      h += (h <<   3);
      h ^= (h >>>  6);
      h += (h <<   2) + (h << 14);
      return h ^ (h >>> 16);
    }
    ReentrantLock对每个segment枷锁
    size()
        会在不上锁的前提逐个Segment计算3次size，如果某相邻两次计算获取的所有Segment的更新次数（每个Segment都与HashMap一样通过modCount跟踪自己的修改次数，
        Segment每修改一次其modCount加一）相等，说明这两次计算过程中无更新操作，则这两次计算出的总size相等，
        可直接作为最终结果返回。如果这三次计算过程中Map有更新，则对所有Segment加锁重新计算Size

    HashMap允许Key和Value为null，而ConcurrentHashMap不允许
    HashMap不允许通过Iterator遍历的同时通过HashMap修改，而ConcurrentHashMap允许该行为，并且该更新对后续的遍历可见

    JDK8
    基于CAS
    Java 8为进一步提高并发性，摒弃了分段锁的方案，而是直接使用一个大的数组。同时为了提高哈希碰撞下的寻址性能，
    Java 8在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为O(N)）转换为红黑树（寻址时间复杂度为O(long(N))）。其数据结构如下图所示

   ![jdk8](../images/concurrenthashmap_java8.png)

    寻址方式
        通过Key的哈希值与数组长度取模确定该Key在数组中的索引
        作者认为引入红黑树后，即使哈希冲突比较严重，寻址效率也足够高
        static final int spread(int h) {
          return (h ^ (h >>> 16)) & HASH_BITS;
        }

    同步方式
        对于put操作，如果Key对应的数组元素为null，则通过CAS操作将其设置为当前值。如果Key对应的数组元素（也即链表表头或者树的根元素）不为null，则对该元素使用synchronized关键字申请锁，然后进行操作。
        如果该put操作使得当前链表长度超过一定阈值，则将该链表转换为树，从而提高寻址效率
    size
        put方法和remove方法都会通过addCount方法维护Map的size。size方法通过sumCount获取由addCount方法维护的Map的size。

#### ConcurrentLinkedDeque
#### ConcurrentSkipListMap
#### ConcurrentSkipListSet

### 线程池的实现原理
[参考](https://itimetraveler.github.io/2018/02/13/%E3%80%90Java%E3%80%91%E7%BA%BF%E7%A8%8B%E6%B1%A0ThreadPoolExecutor%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/)

### 线程池优化
[参考](https://www.cnblogs.com/jianzh5/p/6437315.html)

### 线程池的最大线程数目根据什么确定
    Nthreads=Ncpu*(1+w/c)
    W/C=等待时间 与 计算时间 的比率

    IO密集型：
        一般情况下，如果存在IO，那么肯定w/c>1（阻塞耗时一般都是计算耗时的很多倍）,但是需要考虑系统内存有限（每开启一个线程都需要内存空间），这里需要上服务器测试具体多少个线程数适合（CPU占比、线程数、总耗时、内存消耗）。如果不想去测试，保守点取1即，Nthreads=Ncpu*(1+1)=2Ncpu。这样设置一般都OK
    计算密集型
        假设没有等待w=0，则W/C=0. Nthreads=Ncpu
    线程等待时间所占比例越高，需要越多线程。线程CPU时间所占比例越高，需要越少线程
### 题目

#### 编写两个线程，一个线程打印1~25，另一个线程打印字母A~Z，打印顺序为12A34B56C……5152Z，要求使用线程间的通信
   [参考](https://blog.csdn.net/u011514810/article/details/77131296)

    思路：
    1、synchronized、notify、wait
    方法 m1，m2
    共享变量

